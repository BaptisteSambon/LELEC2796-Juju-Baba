{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "y7JT-OVmRIvz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Import Sionna\n",
        "try:\n",
        "    import sionna\n",
        "except ImportError as e:\n",
        "    # Install Sionna if package is not already installed\n",
        "    import os\n",
        "    os.system(\"pip install sionna\")\n",
        "    import sionna\n",
        "import tensorflow as tf\n",
        "\n",
        "from utils import *\n",
        "import matplotlib.pyplot as plt\n",
        "from termcolor import colored\n",
        "from scipy.special import erfc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "irr0-_DsP2od"
      },
      "outputs": [],
      "source": [
        "tx_params = {\n",
        "    \"nUsers\" : 3,\n",
        "    \"powerAllocation\" : np.zeros(3),\n",
        "    \"nCode\" : 120,\n",
        "    \"kCode\" : 60,\n",
        "    \"codingRate\": 1/2,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "31uYatDRQy6u"
      },
      "outputs": [],
      "source": [
        "nmodbits = 2\n",
        "binary_source = sionna.utils.BinarySource()\n",
        "constellation = sionna.mapping.Constellation(\"qam\", nmodbits)\n",
        "encoder = sionna.fec.conv.ConvEncoder(rate=tx_params[\"codingRate\"])\n",
        "mapper = sionna.mapping.Mapper(constellation=constellation)\n",
        "channel = sionna.channel.AWGN()\n",
        "demapper = sionna.mapping.Demapper(\"app\",\"qam\", nmodbits, hard_out=True,  dtype=tf.complex128)\n",
        "decoder = sionna.fec.conv.ViterbiDecoder(encoder=encoder, rate=tx_params[\"codingRate\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "L8YWTLAHSh9t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data_out:  (60,)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "could not broadcast input array from shape (120,) into shape (60,)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\bapti\\OneDrive\\Documents\\LELEC2796 - Wireless Communication\\Git\\LELEC2796-Juju-Baba\\NOMA.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/bapti/OneDrive/Documents/LELEC2796%20-%20Wireless%20Communication/Git/LELEC2796-Juju-Baba/NOMA.ipynb#W3sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m y_user \u001b[39m=\u001b[39m viterbi_decoder(R1,R0,symb_R1, symb_R0,len_b, y\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/bapti/OneDrive/Documents/LELEC2796%20-%20Wireless%20Communication/Git/LELEC2796-Juju-Baba/NOMA.ipynb#W3sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m \u001b[39m#y_user = tf.convert_to_tensor(y.numpy().reshape((1, len(y))))\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/bapti/OneDrive/Documents/LELEC2796%20-%20Wireless%20Communication/Git/LELEC2796-Juju-Baba/NOMA.ipynb#W3sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m y_decoded[idx_user, :] \u001b[39m=\u001b[39m y_user\u001b[39m#.numpy()\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/bapti/OneDrive/Documents/LELEC2796%20-%20Wireless%20Communication/Git/LELEC2796-Juju-Baba/NOMA.ipynb#W3sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m \u001b[39m#y_user_encoded = encoder(y_user)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/bapti/OneDrive/Documents/LELEC2796%20-%20Wireless%20Communication/Git/LELEC2796-Juju-Baba/NOMA.ipynb#W3sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m (u_s,u_c) \u001b[39m=\u001b[39m conv_encoder(y_user,R1,R0,out_R1,out_R0,len_b)\n",
            "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (120,) into shape (60,)"
          ]
        }
      ],
      "source": [
        "\n",
        "ebn0 = np.arange(0, 21, 1) #dB\n",
        "snr_db = ebn0 + 10*np.log10(tx_params[\"codingRate\"]) + 10*np.log10(nmodbits) #dB\n",
        "nb_seq =1000\n",
        "alpha = 0\n",
        "\n",
        "BER_coded = np.zeros(len(ebn0))\n",
        "BER_uncoded = np.zeros(len(ebn0))\n",
        "\n",
        "gn = np.array([1, 1])\n",
        "gd = np.array([1, 1, 1])\n",
        "R1,R0,out_R1,out_R0 = poly2trellis(gn,gd)\n",
        "d = 1\n",
        "out_R1_tf = tf.convert_to_tensor(out_R1)\n",
        "out_R0_tf = tf.convert_to_tensor(out_R0)\n",
        "symb_R1 = mapper(out_R1_tf).numpy()\n",
        "symb_R0 = mapper(out_R0_tf).numpy()\n",
        "\n",
        "for ii in range(len(snr_db)) :\n",
        "\n",
        "  BER_coded_ii = np.zeros(nb_seq)\n",
        "  BER_uncoded_ii = np.zeros(nb_seq)\n",
        "\n",
        "  var_noise = 1/(10**(0.1*snr_db[ii]))\n",
        "  len_b = tx_params[\"kCode\"]\n",
        "\n",
        "  for jj in range(nb_seq) :\n",
        "\n",
        "    # NOMA Power allocation\n",
        "    Ptot_db = 15 # total power allocation in dB\n",
        "    Ptot = 10**(0.1*Ptot_db)\n",
        "    #polynomial = np.array([1, 3, 3, -1*Ptot/var_noise])\n",
        "    polynomial = np.array([1, 2, 1, -1*Ptot])\n",
        "    roots = np.roots(polynomial) # roots of polynomial\n",
        "    x = roots[np.isreal(roots)][-1] # keep only real root\n",
        "\n",
        "    #Evaluate the root \n",
        "    #print(polynomial[0]*x**3 + polynomial[1]*x**2 + polynomial[2]*x + polynomial[3]\t)\n",
        "\n",
        "    if(len(roots[np.isreal(roots)])>1) : \n",
        "      print(\"More than 2 roots found in polynomial\")\n",
        "\n",
        "    # P1 = x\n",
        "    # P2 = ((x**2) + x)\n",
        "    # P3 = ((x**3) + 2*(x**2) + x)\n",
        "\n",
        "    # P1 = 10*(var_noise)\n",
        "    # P2 = 10*(P1 + var_noise)\n",
        "    # P3 = 10*(P1 + P2 + var_noise)\n",
        "\n",
        "    # factor = Ptot/(P1+P2+P3)\n",
        "    # P1 *= factor\n",
        "    # P2 *= factor\n",
        "    # P3 *= factor\n",
        "\n",
        "    # P3 = x**3 + x**2\n",
        "    # P2 = x**2 \n",
        "    # P1 = x\n",
        "\n",
        "    mu = (1 + (Ptot)/var_noise)**(-1/tx_params[\"nUsers\"])\n",
        "    alpha1 = ((mu**(1-1))*(1-mu))/(1-mu**(tx_params[\"nUsers\"]))\n",
        "    alpha2 = ((mu**(2-1))*(1-mu))/(1-mu**(tx_params[\"nUsers\"]))\n",
        "    alpha3 = ((mu**(3-1))*(1-mu))/(1-mu**(tx_params[\"nUsers\"]))\n",
        "    P1 = alpha3*Ptot\n",
        "    P2 = alpha2*Ptot\n",
        "    P3 = alpha1*Ptot\n",
        "\n",
        "    tx_params[\"powerAllocation\"] = np.array([P3, P2, P1])\n",
        "    if jj==1 : \n",
        "    #  fig = plt.figure()\n",
        "    #  x = np.linspace(-10, 10, 100)\n",
        "    #  plt.plot(x, polynomial[0] + polynomial[1]*x + polynomial[2]*(x**2) + polynomial[3]*(x**3))\n",
        "    #  plt.grid()\n",
        "    #  plt.show()\n",
        "     print(\"Noise variance: \", var_noise)\n",
        "     #print(roots)\n",
        "     print(\"P1: \", P1, \"P2: \", P2, \"P3: \", P3)\n",
        "     print(\"Natural scale: \", P1/var_noise, P2/(P1 + var_noise), P3/(P2 + P1 + var_noise))\n",
        "     print(\"Log scale: \", 10*np.log10(P1/var_noise), 10*np.log10(P2/(P1 + var_noise)), 10*np.log10(P3/(P2 + P1 + var_noise)))\n",
        "     print(\"Sum of powers: \", P1+P2+P3)\n",
        "\n",
        "\n",
        "    data = np.zeros((tx_params[\"nUsers\"], tx_params[\"nCode\"])) # nCode noramlement (à changer après)\n",
        "    b = binary_source([tx_params[\"nUsers\"], tx_params[\"kCode\"]])\n",
        "    #c = encoder(b)\n",
        "    # encoding\n",
        "    b_array = b.numpy()\n",
        "    c_array = np.zeros((tx_params[\"nUsers\"], 2*len(b_array[0])))\n",
        "    for idx_user in range(tx_params[\"nUsers\"]):\n",
        "      (u_s,u_c) = conv_encoder(b_array[idx_user],R1,R0,out_R1,out_R0,len_b)\n",
        "      c_array[idx_user] = np.reshape(np.transpose([u_s,u_c]),(2*len(u_s),))\n",
        "    c = tf.convert_to_tensor(c_array)\n",
        "    #c=b \n",
        "    x = mapper(c)\n",
        "    data = x.numpy()\n",
        "\n",
        "    data_out = NOMA(data, tx_params)\n",
        "    \n",
        "    h = Rayleigh_canal(alpha, len(data_out))\n",
        "    n = (1j*np.random.normal(scale=np.sqrt(var_noise/2), size=data_out.shape)+np.random.normal(scale=np.sqrt(var_noise/2),  size=data_out.shape))\n",
        "\n",
        "    #y_canal = h*data_out+n\n",
        "    #y_canal = channel([data_out, var_noise])\n",
        "    y_canal = data_out + n\n",
        "\n",
        "    # Reception \n",
        "    #y_canal = y_canal.reshape(1, len(y_canal))\n",
        "    #y_received = y_canal/h\n",
        "    y_received = y_canal\n",
        "    y_decoded = np.zeros((tx_params[\"nUsers\"], tx_params[\"kCode\"]))\n",
        "    y_demapped = np.zeros((tx_params[\"nUsers\"], tx_params[\"nCode\"])) # nCode noramlement (à changer après)\n",
        "    # SIC \n",
        "    for idx_user in range(tx_params[\"nUsers\"]):\n",
        "\n",
        "      y = demapper([tf.convert_to_tensor(y_received), var_noise])\n",
        "\n",
        "      y_demapped[idx_user, :] = y.numpy()\n",
        "\n",
        "      #y_user = decoder(tf.convert_to_tensor(y.numpy().reshape((1, tx_params[\"nCode\"]))))\n",
        "      y_user = viterbi_decoder(R1,R0,symb_R1, symb_R0,len_b, y.numpy())\n",
        "      #y_user = tf.convert_to_tensor(y.numpy().reshape((1, len(y))))\n",
        "\n",
        "      y_decoded[idx_user, :] = y_user#.numpy()\n",
        "\n",
        "      #y_user_encoded = encoder(y_user)\n",
        "      (u_s,u_c) = conv_encoder(y_user,R1,R0,out_R1,out_R0,len_b)\n",
        "      y_user_encoded = np.reshape(np.transpose([u_s,u_c]),(2*len(u_s),))\n",
        "      y_user_encoded = tf.convert_to_tensor(y_user_encoded.reshape((1, len(y_user_encoded))))\n",
        "    \n",
        "      y_received = y_received - mapper(y_user_encoded).numpy()[0]*np.sqrt(tx_params[\"powerAllocation\"][idx_user])\n",
        "\n",
        "    y_demapped_tf = tf.convert_to_tensor(y_demapped)\n",
        "    y_decoded_tf = tf.convert_to_tensor(y_decoded)\n",
        "    c_hat = tf.cast(tf.less(0.0, y_demapped_tf), tf.float32)\n",
        "    b_hat = tf.cast(tf.less(0.0, y_decoded_tf), tf.float32)\n",
        "    ber_uncoded = sionna.utils.metrics.compute_ber(c, c_hat)\n",
        "    ber_coded = sionna.utils.metrics.compute_ber(b, b_hat)\n",
        "\n",
        "    BER_coded_ii[jj] = ber_coded.numpy()\n",
        "    BER_uncoded_ii[jj] = ber_uncoded.numpy()\n",
        "  \n",
        "  BER_coded[ii] = np.mean(BER_coded_ii)\n",
        "  BER_uncoded[ii] = np.mean(BER_uncoded_ii)\n",
        "\n",
        "  print(\"Eb/N0 = \" + str(ebn0[ii]) +  \"dB, BER uncoded = \" +  str(BER_uncoded[ii]) + \", BER coded = \" + str(BER_coded[ii]))\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot\n",
        "\n",
        "plt.figure()\n",
        "plt.semilogy(snr_db, BER_coded, \"v-\", label=\"coded\", color=\"black\")\n",
        "plt.semilogy(snr_db, BER_uncoded, \"D-\", label=\"NOMA (with fading)\", color=\"black\")\n",
        "ber = (1/2)*erfc(np.sqrt(10**(0.1*snr_db)/2))\n",
        "plt.plot(snr_db, ber, label=\"AWGN\", color=\"black\")\n",
        "plt.xlabel(\"SNR [dB]\")\n",
        "plt.ylabel(\"BER\")\n",
        "plt.xscale(\"linear\")\n",
        "plt.yscale(\"log\")\n",
        "plt.grid(which=\"both\")\n",
        "plt.legend()\n",
        "#plt.xlim([0, 15])\n",
        "plt.ylim([10**(-8), 0.5])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
